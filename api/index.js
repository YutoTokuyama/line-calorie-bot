import fetch from "node-fetch";
import { v2 as cloudinary } from "cloudinary";

export default async function handler(req, res) {
  if (req.method !== "POST") {
    return res.status(200).send("OK");
  }

  const event = req.body.events?.[0];
  if (!event) return res.status(200).send("No event");

  const replyToken = event.replyToken;
  const message = event.message;

  const reply = async (text) => {
    await fetch("https://api.line.me/v2/bot/message/reply", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.LINE_CHANNEL_ACCESS_TOKEN}`,
      },
      body: JSON.stringify({
        replyToken,
        messages: [{ type: "text", text }],
      }),
    });
  };

  // --- ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ---
  if (message.type === "text") {
    const userText = message.text;

    const aiRes = await fetch("https://api.openai.com/v1/responses", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: "gpt-4.1-mini",
        input: [
          {
            role: "user",
            content: `
ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãŒã€Œé£Ÿæãƒ»æ–™ç†åã€ã®å ´åˆã¯ã€
1. æ–™ç†å
2. æ¨å®šã‚«ãƒ­ãƒªãƒ¼ï¼ˆkcalï¼‰
3. PFCï¼ˆãŸã‚“ã±ãè³ªgãƒ»è„‚è³ªgãƒ»ç‚­æ°´åŒ–ç‰©gï¼‰

ã‚’æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãå‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

é£Ÿæã‚„æ–™ç†ã¨é–¢ä¿‚ãªã„å†…å®¹ã®å ´åˆã¯ã€
ã€Œæ–™ç†ã‚„é£Ÿæã‚’ãƒ†ã‚­ã‚¹ãƒˆã‹å†™çœŸã§é€ã‚‹ã¨ã€ç›®å®‰ã‚«ãƒ­ãƒªãƒ¼ã¨PFCã‚’çŸ¥ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€
ã¨ã ã‘è¿”ã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆï¼š
ã€Œ${userText}ã€
`,
          },
        ],
      }),
    });

    const data = await aiRes.json();
    const text =
      data.output?.[0]?.content?.[0]?.text ||
      "è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ";

    await reply(text);
    return res.status(200).end();
  }

  // --- ç”»åƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ---
  if (message.type === "image") {
    await reply("ğŸ“¸ è§£æä¸­ã§ã™â€¦å°‘ã—ãŠå¾…ã¡ãã ã•ã„");

    // ç”»åƒå–å¾—
    const imageRes = await fetch(
      `https://api-data.line.me/v2/bot/message/${message.id}/content`,
      {
        headers: {
          Authorization: `Bearer ${process.env.LINE_CHANNEL_ACCESS_TOKEN}`,
        },
      }
    );

    const buffer = await imageRes.buffer();

    // Cloudinaryã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    const uploadRes = await new Promise((resolve, reject) => {
      cloudinary.uploader.upload_stream(
        {
          upload_preset: process.env.CLOUDINARY_UPLOAD_PRESET,
        },
        (error, result) => {
          if (error) reject(error);
          else resolve(result);
        }
      ).end(buffer);
    });

    // AIè§£æ
    const aiRes = await fetch("https://api.openai.com/v1/responses", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: "gpt-4.1-mini",
        input: [
          {
            role: "user",
            content: [
              { type: "input_text", text: "ã“ã®æ–™ç†ã®ã‚«ãƒ­ãƒªãƒ¼ã¨PFCï¼ˆãŸã‚“ã±ãè³ªãƒ»è„‚è³ªãƒ»ç‚­æ°´åŒ–ç‰©ï¼‰ã‚’æ¨å®šã—ã¦ã€æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãå‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚" },
              { type: "input_image", image_url: uploadRes.secure_url },
            ],
          },
        ],
      }),
    });

    const data = await aiRes.json();
    const text =
      data.output?.[0]?.content?.[0]?.text ||
      "è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ";

    await reply(text);
    return res.status(200).end();
  }

  return res.status(200).end();
}
